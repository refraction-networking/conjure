\documentclass[sigconf]{acmart}

\settopmatter{printacmref=true,printfolios=true}

\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage[font=small]{caption}
\usepackage{subcaption}
\usepackage{xspace}
\usepackage{dblfloatfix} % magic
\usepackage{balance}
%\usepackage{paralist}
\usepackage{wasysym}
\usepackage{xparse}
\NewDocumentCommand{\rot}{O{45} O{1em} m}{\makebox[#2][l]{\rotatebox{#1}{#3}}}%
\urlstyle{rm}

% From CCS template:
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08emT\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

% Fix URL hyphenation (AH 12/2008)
\def\UrlBreaks{\do-\do\.\do\@\do\\\do\!\do\_\do\|\do\;\do\>\do\]%
 \do\)\do\,\do\?\do\'\do+\do\=\do\#}
\def\UrlBigBreaks{\do\:\do\/}%

\newcommand{\todo}[1]{}
\renewcommand{\todo}[1]{{\color{red} TODO: {#1}}}
\newcommand{\TODO}[1]{}
\renewcommand{\TODO}[1]{{\color{red} TODO: {#1}}}
\newcommand{\TK}{}
\renewcommand{\TK}{{\color{red}TK}\xspace}

\renewcommand{\paragraph}[1]{\smallskip\noindent\textbf{#1\quad}}

\copyrightyear{2019}
\acmYear{2019}
\acmConference[CCS '19]{2019 ACM SIGSAC Conference on Computer and Communications Security}{November 11--15, 2019}{London, United Kingdom}
\acmBooktitle{2019 ACM SIGSAC Conference on Computer and Communications Security (CCS '19), November 11--15, 2019, London, United Kingdom}
\acmPrice{15.00}
\acmDOI{10.1145/3319535.3363218}
\acmISBN{978-1-4503-6747-9/19/11}
\setcopyright{rightsretained}

\include{figures}

\begin{document}

%\fancyhead{} % From CCS template.

\title{Conjure: Summoning Proxies from Unused Address Space}

\author{Sergey Frolov}\affiliation{University of Colorado Boulder}
\author{Jack Wampler}\affiliation{University of Colorado Boulder}
\author{Sze Chuen Tan}\affiliation{UIUC}
\author{J. Alex Halderman}\affiliation{University of Michigan}
\author{Nikita Borisov}\affiliation{UIUC}
\author{Eric Wustrow}\affiliation{University of Colorado Boulder}

\newcommand{\scheme}{Conjure\xspace}

%-------------------------------------------------------------------------------
\begin{abstract}
%-------------------------------------------------------------------------------
Refraction Networking (formerly known as ``Decoy Routing'') has
emerged as a promising next-generation approach for circumventing
Internet censorship. Rather than trying to hide individual
circumvention proxy servers from censors, proxy functionality is
implemented in the core of the network, at cooperating ISPs in
friendly countries. Any connection that traverses these ISPs could be
a conduit for the free flow of information, so censors cannot easily
block access without also blocking many legitimate sites.  While one
Refraction scheme, TapDance, has recently been deployed at ISP-scale,
it suffers from several problems: a limited number of ``decoy'' sites
in realistic deployments, high technical complexity, and undesirable
tradeoffs between performance and observability by the censor. These
challenges may impede broader deployment and ultimately allow censors to
block such techniques.

We present \scheme, an improved Refraction Networking approach
that overcomes these limitations by leveraging unused address space at
deploying ISPs. Instead of using real websites as the decoy destinations
for proxy connections, our scheme connects to IP addresses where no 
web server exists leveraging proxy functionality from the core of the network.
These phantom hosts are difficult for a censor to distinguish from
real ones, but can be used by clients as proxies.  We define the
\scheme protocol, analyze its security, and evaluate a
prototype using an ISP testbed.
Our results suggest that \scheme can be harder to block
than TapDance, is simpler to maintain and deploy,
and offers substantially better network performance.

\end{abstract}

\begin{CCSXML}
  <ccs2012>
  <concept>
  <concept_id>10003033.10003083.10003014</concept_id>
  <concept_desc>Networks~Network security</concept_desc>
  <concept_significance>300</concept_significance>
  </concept>
  <concept>
  <concept_id>10003456.10003462.10003480</concept_id>
  <concept_desc>Social and professional topics~Censorship</concept_desc>
  <concept_significance>300</concept_significance>
  </concept>
  </ccs2012>
\end{CCSXML}

\ccsdesc[300]{Networks~Network security}
\ccsdesc[300]{Social and professional topics~Censorship}

\keywords{anticensorship, proxies, network security}


\maketitle


%-------------------------------------------------------------------------------
\section{Introduction}
%-------------------------------------------------------------------------------
% 1.5-2 pages

\FigHighLevel

%Censorship circumvention still important
%-More countries blocking
%-Existing countries blocking more
%Internet censorship continues to hamper social progress throughout the world.

Over half of Internet users globally
now live in countries that block political, social, or religious content
online~\cite{fotn2018}.
%Existing circumvention strategies on shaky ground
%-domain fronting going away
%-active probing of existing proxies
%-Cenosrs fingerprinting known protocols
Meanwhile, many popular tools and techniques for circumventing such censorship
become ineffective, because censors have evolved new ways to block them~\cite{ensafi-tor,great-cannon}
or infrastructure they rely on has become unavailable.



For example, domain fronting~\cite{meek} was a popular circumvention
strategy used by meek (in Tor), as well as by the Signal secure messaging app to
get around censorship in countries where it was
blocked~\cite{signal,signal-domain-fronting}.
But in May~2018, Google and Amazon made both technical and policy changes to
their cloud infrastructures that removed support for domain
fronting~\cite{aws-front}. While meek
continues to use other cloud providers that (for now) continue to allow domain
fronting, Signal abandoned the strategy altogether~\cite{signal-back-on-front}.
There is an urgent need for new, more robust approaches to circumvention.

%Combined with censors' constant improvements in discovery and blocking
%techniques~\cite{ensafi-tor,great-cannon}, ...

%Importance of Refraction Networking
%-what it is, how it solves many of the above problems
%-acknowledge challenge of ISP deployment, cite TapDance deployment as only refraction technology that has overcome this challenge so far
A family of techniques called Refraction Networking~\cite{telex11,cirripede11,curveball11,tapdance14,rebound15,slitheen16,waterfall17}, formerly known
as Decoy Routing, has made promising steps towards that goal.
These techniques operate in the network's core, at cooperating Internet Service Providers
(ISPs) outside censoring countries~\cite{refraction-site}.  Clients access circumvention services by connecting to a ``decoy site''---any uncensored website for which the connection travels over a participating ISP\@.  Upon recognizing a steganographic signal from the client, the ISP modifies the connection response to return censored content requested by the user.
Censors cannot easily block access without also blocking legitimate connections to the decoy sites---collateral damage that may be prohibitive for censors if Refraction Networking is widely deployed~\cite{robinson2013collateral}.
\looseness=-1

However, deploying such schemes is more difficult than with most
edge-based circumvention techniques, since ISPs must be convinced to
operate the systems in their production networks.  To date, only
TapDance~\cite{tapdance14}, one of six Refraction Networking
proposals, has been deployed at ISP scale~\cite{frolov2017isp}.

TapDance was designed for ease of deployment.
Instead of in-line network devices required by earlier schemes, it
calls for only a passive tap.
This ``on-the-side'' approach, though much friendlier from an ISP's
perspective, leads to major challenges when interposing in an ongoing
client-to-decoy connection:

\begin{itemize}
\item Implementation is complex and error-prone, requiring kernel
  patches or a custom TCP stack.
\item To avoid detection, the system must carefully mimic
  subtle features of each decoy's TCP and TLS behavior.
\item The architecture cannot resist active probing attacks, where the
  censor sends specially crafted packets to determine whether a
  suspected connection is using TapDance.
\item Interactions with the decoy's network stack limit the length and
  duration of each connection, forcing TapDance to multiplex
  long-lived proxy connections over many shorter decoy
  connections. This adds overhead and creates a traffic pattern
  that is challenging to conceal.
\end{itemize}

%Challenges remain in Tapdance:
%-Censor can fingerprint decoy sites
%-Decoys themselves are limited (e.g. a few dozen in many cases)
%-Can't have long-lived connections (performance and observability issue)
%-Other performance limits (upload limit, TCP window size)

%% AH: I'm not sure I buy this limited decoys argument. If there are
%% few decoys, there is little collateral damage of blocking
%% everything in the AS, and \scheme is at a big disadvantage too.
%The use of real-world decoy sites also presents practical problems: If
%decoys are limited or not particularly important, it may be easy for a
%censor to block them altogether without much collateral damage.

%Dark decoys solve these issues
%-Create new decoys from ``dark'' (unused) address space
%-Clients register (via TapDance-like or other robust protocol (email, blockchain, whatever))
%-Connect to custom IP address, talk whatever protocol client/station agrees on

\smallskip
\noindent\textbf{Conjure}\enskip
In this paper, we present \scheme, a Refraction
Networking protocol that overcomes these challenges while retaining
TapDance's ISP-friendly deployment requirements
Our key innovation is an architecture that avoids
having to actively participate in client-to-decoy connections.

%\TODO{more precise:}
In our scheme (Figure~\ref{fig:highlevel}), clients
register their intentions to connect to phantom hosts in the ``dark''
or unused address space of the deploying ISP. Once registered, clients
can connect to these phantom hosts IP addresses as if they were real
proxy servers. The \scheme station (deployed at an ISP) acts as the other end of these connections, and
responds as if it were a legitimate site or service. To the censor,
these phantom hosts appear as legitimate sites or services, and even
active probes will not reveal information that would allow the censor to
block them.

%% requests service
%% by embedding a steganographic registration message in a TLS handshake
%% with a decoy site. This message, which the \scheme station can passively
%% observe using a private key, uniquely determines an IP address within
%% the ISP's address space. If there is no server running at that address,

%One-time use address advantages:
%-Censor cannot actively probe ahead of time (especially in IPv6), making it hard to fingerprint
%-Decoys are now virtually unlimited (or limited only by address space)
%-Connection can live as long as we want
%-No pesky TCP/TapDance-y limits

Phantom hosts are cheap to connect to, and greatly expand the 
number of viable proxy endpoints that a censor must consider. This increases the cost for censors to
block, as they must detect and block in real time. Meanwhile, even a censor that
could theoretically detect 90\% of phantom hosts with confidence does not significantly reduce the
effectiveness of a circumvention system, giving \scheme an advantage in the censor/circumventor
cat-and-mouse game.

\scheme supports both IPv4 and IPv6,
though we note that the technique is especially
powerful in IPv6, where censors cannot exhaustively scan the address space
ahead of time to identify addresses that change behavior.
Because we fully control the proxy transport, connections can live as
long as needed, without the complexity faced by TapDance.

%TODO:
%Requirements/Challenges
%-Censor can't be able to distinguish between dark decoy and legitimate hosts
%    (otherwise they block all dark decoys)
%    -Includes active probing: censor shouldn't be able to register existing IP
%-Disruption avoidence: Want to pickup even for used addresses
%    -Otherwise, censor probes to find truly unused address space and blocks
%    -But can't disrupt legitimate services
%    -Can overcome by limiting pickup to the registering client (but spoofing challenges...)
%    -Note: also likely solved by the client-sends-SNI in the Mask site application...

% We implement it, it works...

% TODO: modularity?

We introduce the \scheme protocol (Section~\ref{sec:architecture})
and analyze its security, finding that it resists a broader
range of detection attacks than TapDance.
We have implemented \scheme (Section~\ref{sec:implementation})
and deployed it on a 20~Gbps ISP testbed similar to the TapDance
deployment~\cite{frolov2017isp}.  Compared to TapDance, we find that
\scheme has reduced complexity and substantially improved performance
(Section~\ref{sec:evaluation}): on average, \scheme has 20\% lower latency,
14\% faster download bandwidth, and over 1400 times faster upload bandwidth.
In addition, \scheme is significantly more
flexible than existing Refraction Networking protocols, allowing maintainers to
respond to future censor techniques with greater agility.
We believe that these advantages will
make \scheme a strong choice for future Refraction Networking deployments.

We have released the open source implementation of the Conjure client at 
\url{https://github.com/refraction-networking/gotapdance/tree/dark-decoy}.

%download: dd - td: 5947790000 - 5219112999 = 14% faster down
% upload:  5088330000/3500000.0 = 1453x upload
% latency: td avg 297ms, dd avg 237ms = 20% lower latency

\input{background.tex}


\section{Threat Model}
% 0.25 page


Our deployment model is identical to that of TapDance: we only require a passive
tap at the deploying ISP, and the ability to inject (spoofed) traffic from phantom
hosts.
Furthermore, we assume
asymmetric routing (i.e. that the tap might only see packets from but not to the
client).
However, we assume a stronger threat model for the adversary than
TapDance, as our design resists active attacks.

We assume the censor can block arbitrary IP addresses and networks, but faces a
cost in doing so if it blocks potentially useful resources. In particular, we
assume it is difficult for the censor to have complete knowledge of legitimate
addresses used, and so instead resorts to a blacklist approach to blocking
proxies and objectionable content.
Whitelists are expensive for censors to maintain and can stifle
innovation, and are rarely employed by country-level censors.
%TODO: cite OONI? censored planet?

We assume that the censor can know what network the \scheme station(s) are
deployed in and the prefixes phantom hosts are selected from, but that blocking those
networks outright brings a collateral
damage the censor is unwilling to suffer. Instead, the censor aims to identify
the addresses that are phantom hosts, and block only those. We note this
assumption supposes that the censor does not mount effective routing
decoy attacks~\cite{rad12,true-cost-rad}; we discuss these attacks further in Section~\ref{sec:placement-rad}.

We allow the censor access to the client to register and use its own phantom hosts, 
so the system should ensure that these will not reveal the phantom hosts of other users. The
censor can also actively probe addresses that it sees users accessing, and can
employ tools such as ZMap~\cite{zmap13} to scan large network blocks, excepting
large IPv6 prefixes (e.g. a /32 IPv6 prefix contains $2^{96}$ addresses).

Finally, we assume the censor can replay or preplay any connections that it
suspects involve phantom hosts (or their registration) in an attempt to confirm.
However, the censor wishes to avoid disrupting any connections before it
knows for certain they are from \scheme clients, lest they disrupt legitimate
connections. This means that injecting false data or corrupting TLS sessions is
outside the scope of the censor, but that the censor can send non-disruptive
probes (such as stale TCP acknowledgments) that would normally
be ignored. We emphasize that TapDance is observable by censors that can send
TCP packets in suspected connections, but that our protocol is robust against
this class of censor.

%-Censor can block arbitrary addresses (or networks), but faces a cost in doing so (collateral damage)
%-Censor can know what network deploys the dark decoy station
%-Censor knows the dark decoy prefixes distributed in the client, but they contain legitimate hosts
%-Censor can use the client
%-Censor can active probe limited sets, but cannot enumerate the entire prefix (i.e. IPv6 /32)
%-Censor can active probe or (p)replay connections it suspects


\section{Architecture}
\label{sec:architecture}
% 3 pages

\scheme involves two high-level steps. First, clients \textbf{register} with a 
\scheme station deployed at an ISP, and derive a phantom host IP address from 
a seed shared in the registration. Then, clients \textbf{connect} 
to the agreed upon phantom address, and the station listening on the tap 
relays the client's traffic to a local application. The application brokers 
traffic to a proxy application specified by the client in their registration 
providing a probe resistant tunnel. Figure~\ref{fig:overview} describes a 
high-level overview of the \scheme registration and connection behavior.

Similar to TapDance~\cite{tapdance14}, our design does not require expensive in-line
flow blocking and is accomplished with only a passive tap at the ISP, imparting
little to no burden on their infrastructure and service reliability.
Our architecture is also modular, in that the registration and connection steps operate
independently, allowing a wide range of flexibility to evade censors. We
describe each of these components, and then describe our implementation and
deployment in Section~\ref{sec:implementation}.

\FigOverview

\subsection{Registration}
\label{sec:registration}
We use a form of Refraction Networking similar to TapDance to register directly with
the station, though \scheme registration is significantly simpler and more difficult
to detect than vanilla TapDance. This is because registration flows are unidirectional; 
a client communicates their intent to register to the station without any 
response from the station itself. This makes registration flows very difficult to detect as they 
can be sent to any site hosted behind the ISP, and display no evidence of proxy behavior. 

While this model of registration gives the client no definitive indication that their 
registration was successful, the client can attempt to register
multiple times concurrently with the same information, 
and expect that one gets through. Alternatively clients can register intent to use the 
proxy in other covert ways. For instance, they could use email~\cite{SWEET-ToN} or any 
other existing intermittently available proxies to register.

A registration connection is sent to a \textbf{registration decoy}: any site that 
supports TLS behind the ISP relative to the client. The client completes the handshake,
and sends a normal HTTPS request that embeds a ciphertext tag in the payload. 
\scheme leverages the same steganographic technique as TapDance to encode the 
ciphertext~\cite[\S3]{tapdance14}, however we send a complete request allowing the
registration decoy to respond or close the connection. The tag is encrypted such 
that it is only visible to the station. The \scheme station passively observes
tagged flows obviating the need to mimic the decoy. In addition, more potential 
decoys can be used in comparison to TapDance, as there is no need to exclude decoys that 
have timeouts or TCP windows unfavorable for keeping connections open. In our 
deployment, this results in a modest increase of 25\% more decoys that could be 
used than in TapDance.


The tag contains a public key (encoded to be indistinguishable from random using
Elligator~\cite{elligator}), and a message encrypted under the shared secret
derived from a Diffie-Hellman key exchange with the station's long-term public key hard-coded
in the client. The station uses its private key to compute the same
shared secret from the (decoded) client public key, and decrypts the message in the
tag. The censor, without knowledge of either the station or client's private
key, cannot derive the shared secret, preventing it from being able to decrypt
the message, or even learn of its existence.


Inside the message, the client communicates a random seed, the covert address 
they would like to connect to, the transport protocol they will use, and other
configuration-specific information, such as flags to signify version, and feature support.
The client and server hash the seed to determine which specific
IP address from the set of shared CIDR prefixes will be used and registered as a phantom host.
It may seem intuitive to instead have the client
send the specific IP address to register, but allowing the client arbitrary
choice also allows the censor to register suspected phantom hosts and block them if
they can be used as proxies.
By using a hash of a seed, the censor would have to pre-image the hash to
obtain a seed it could use to register for a desired IP address.
We discuss the intricacies of phantom IP address selection in
Section~\ref{sec:addr-selection}.

Once the phantom host IP address has been selected, the station watches for
packets with the source address of the original client and the phantom as the destination, 
and forwards them on to the a local application handling transports. The station only 
forwards packets that originate from the IP address of the registering client, making the
 phantom host appear firewalled off to everyone but the client.
We note that censors have been observed taking over client IP
addresses for follow-up probing~\cite{ensafi-tor}. This would allow censors to
hijack registrations if they can connect within the small window between client 
registration and connection. However this only 
allows the censor to communicate to the local application that handles transports, 
it does not connect them to the covert address that the client indicated in their registration. 
Filtering by client IP and phantom IP also prevents censors from enumerating the
address space before hand, as they would have to do so from every potential
client IP address. Simply scanning the prefixes with ZMap~\cite{zmap13} from a
single vantage point would not reveal hosts that only respond to specific IPs
(e.g., firewalled subnets).


\subsection{Transports}
%\TODO{The organization of this into subsubsections and paragraphs is a mess.  Can we flatten it a bit or divide into two sections?}

Once the client has registered, packets sent to the phantom host IP address are
detected at the station and passed to the local \textbf{application} which provides
proxy access to the client. A viable \scheme transport has
two main requirements: first, the protocol it uses with the client 
must be difficult for the censor to \emph{passively detect} and block by traffic
inspection. Second, the endpoint must resist \emph{active probes} by the censor (who
does not know some shared secret). 

Any protocol that satisfies these criteria can be used as an effective transport
with \scheme. In this section, we describe various existing protocols (OSSH and obfs4) as well
as introduce our own (Mask sites, TLS 1.3 eSNI, and phantom WebRTC clients) that
can be used in \scheme, and evaluate how each meet the necessary requirements.
Table~\ref{tab:applications} compares the application protocols. \scheme uses a modular 
approach to transports because research into proxy detection is ongoing.
Having a variety of supported transports gives clients a quick way to pivot and 
maintain proxy access even when new proxy protocol vulnerabilities are discovered.


\subsubsection{Obfuscated SSH}
\label{sec:ossh}

Obfuscated SSH~\cite{ossh} (OSSH) is a protocol that attempts to mask the Secure Shell
(SSH) protocol in a thin
layer of encryption. This makes it difficult for censors to identify using basic
packet filters, as there are no identifying headers or fields
to search for. Instead, Obfuscated SSH clients first send a 16-byte random seed, which
is used to derive a symmetric key that encrypts the rest of the
communication. Early versions of OSSH were passively detectable by censors, who
could observe the random seed and derive the key, allowing them to de-obfuscate the protocol.
These versions also did
not protect against active probing attacks, as a censor could easily create their
own connections to confirm if a server supports the protocol.

More recent versions of OSSH, such as those used by Psiphon~\cite{psiphon}, mix a secret
value into the key derivation, thwarting the naive passive detection/decryption
attack. The secret is distributed out-of-band along with the proxy's address,
and is unknown to a passive or active-probing censor. If a client connects and cannot
demonstrate knowledge of
the secret, the OSSH server does not respond, making it more difficult for
censors to discover OSSH servers via active probing attacks.

% \TODO{We have implemented OSSH as a transport option by integrating with psiphon.}

\subsubsection{obfs4}

\texttt{obfs4}~\cite{obfs4} is a pluggable transport used by
Tor~\cite{tor} designed to resist both passive detection and active probing.
Traffic is obfuscated by encrypting it and sending headerless ciphertext
messages. Similar to OSSH, clients can only connect to \texttt{obfs4}
servers by proving knowledge of a secret. Probing censors that do not have the
secret get no response from \texttt{obfs4} servers, making it difficult for
censors to confirm if a host is a proxy. Server IPs and their corresponding secrets
are normally distributed out-of-band through Tor's bridge distribution system.

During registration, the \scheme client and station could use the registration seed to
derive the \texttt{obfs4} secrets (NODE\_ID and server private/public keys)
needed for the client to connect. The station could then launch an \texttt{obfs4} server
instance locally for the client to connect to as a transport using the
derived secrets. If a censor attempts to connect to the phantom address (even
using the client's IP), it will not receive a response, as it does not know the
registration seed used to derive the \texttt{obfs4} secrets.

Using \texttt{obfs4} as a \scheme application has the added benefit that servers
and secrets do not need to be distributed out-of-band, eliminating one of the
main ways censors currently block existing \texttt{obfs4}
instances~\cite{tor-bridge-blocking-blog}. Instead, each \scheme \texttt{obfs4}
instance is private to its registering client, and there is no public service
that censors can use to discover them.



\subsubsection{TLS}

TLS is a natural protocol for \scheme applications, because it is ubiquitous on
the Internet (making it difficult for censors to block), while also providing
strong cryptographic protection against passive and active network adversaries.
However, there are several challenges to make it robust against censors that
wish to block a particular service.

One challenge is that TLS sends important server-identifying content in plaintext
during the TLS handshake. This includes the Server Name Indication (SNI) in the
Client Hello message that specifies the domain name, and the
X.509 Certificate of the server.

To evade censors, we must send a plausible SNI value (sending no SNI is
uncommon and easily blocked---only 1\% of TLS connections
do not send the SNI extension~\cite{tls-fingerprint}), and we must have the server respond with
a plausible (and corresponding) certificate. Even if we manage to avoid sending
either in the clear (e.g. using session resumption), censors could actively probe
the server in a way that would normally elicit a certificate.


\paragraph{Encrypted SNI}\label{esni}
TLS~1.3~\cite{tls13} offers several features that may greatly simplify 
\scheme transport design. For instance, TLS~1.3 handshakes include encrypted
certificates, removing a strong traffic classification feature.
Unfortunately, TLS~1.3 currently still sends the SNI in the (plaintext) Client
Hello, meaning we would have to choose a realistic domain to fool a censor.

However, there are proposals to encrypt the SNI in the Client Hello~\cite{ietf-tls-esni-02},
though none have been implemented or deployed as of 2019. Nonetheless,
if widely adopted, Encrypted SNI (ESNI) would offer a powerful solution for
\scheme applications by allowing the client to use plain TLS as the transport
while remaining hidden from the censor.
Censors could still try to actively probe with guesses for the SNI,
but servers could respond with generic ``Unknown SNI'' errors. If such responses
were common for incorrect SNI, the censor's efforts to identify phantom hosts
would be frustrated.

\paragraph{Mask Sites}\label{sec:mask-sites}
Another option to overcome active and passive probing attacks is to mimic existing TLS sites.
In this application, we simply forward traffic between any connecting clients
and a real TLS site. To a censor, our phantom site
will be difficult to distinguish from the actual ``mask'' site, making it expensive for
them to block without potentially blocking the real site. TLS connections to the
\scheme station will terminate exactly as connections to the mask site would, with
\scheme acting as a transparent TCP-layer proxy between the client and mask site.
However, this leaves the application unable to introspect on the contents of the
TLS connection to the mask site, as it does not have the client-side shared
secrets, and it cannot overtly man-in-the-middle the connection before knowing
it is communicating with the legitimate client (and not the censor).


To covertly signal to the relaying application, the client changes the shared secret
it derives with the mask site to something that the \scheme station can also derive. The client's first
\texttt{Application Data} packet is thus encrypted under a different secret than
the client/mask site secret. Specifically, the client uses the \textbf{seed}
sent during registration to derive the pre-master secret for the connection.
The new pre-master secret is hashed along with the client and server randoms of the current
(mask site) TLS connection to obtain the master secret that determines
encryption/decryption/authentication keys.

The \scheme station can determine if the client did this by trial decryption with
the master secret derived from the known seed shared at registration. If it succeeds, the
client has proved knowledge of the seed, and the application can
respond as a proxy. If not, the application simply continues to forward data
between the client and the mask site, in case a client's IP was taken over by
a censor after registration. As the censor does not have knowledge of
the \textbf{seed} used in registration, it cannot coerce the application to
appear as anything besides the mask site.

\paragraph{Mask Site Selection}
Selecting which sites to masquerade as must be done carefully to avoid censors
being able to detect obvious choices. For example, if a small university network
has a phantom host in their network that appears to be \texttt{apple.com}, it
would be easy for a censor to block as a likely non-legitimate host. Likewise,
if a phantom host at an IP address pretends to be a domain that
globally resolves to a single (different) IP address, the censor could also trivially
identify and block the phantom host.
Several approaches are possible:

\begin{description}
\item[\rm\em Nearby sites:] pick websites that are
legitimately hosted in or near the network of the phantom host addresses
effectively creating copies of legitimate sites. However, other signals such as 
DNS may reveal the true mask site.

\item[\rm\em Popular sites:] choose mask sites from a list such as the Alexa
top site~\cite{alexa-top500} list. Although it may be wise to avoid
sites that are obviously not hosted in the phantom host address range, such as
large companies that run their own data centers and own their own ASN.
The list could also be filtered to domains that resolve to different IP
addresses from different vantage points, making it harder for a censor to know
if a phantom host corresponds to a domain's IP.

\item[\rm\em Passive observation:] collect sites by passively observing DNS requests, TLS
SNI, or certificates that pass by at the network tap. This would allow for building a realistic set
of sites that are plausibly in the vicinity of the phantom host addresses
that pass by the tap. 

\end{description}

In practice, clients can often try multiple phantom hosts/mask sites over
several attempts, as blocking the client outright may negatively impact other
unrelated users behind the same network (e.g. in the case of NAT). Thus, even a
censor that can block most but not all mask site usage (i.e. by employing 
website fingerprinting) only delays access, and doesn't prevent it outright.

\subsubsection{Phantom WebRTC Clients}
\label{sec:webrtc}

Phantom hosts could also pretend to be clients instead of servers. This may
potentially give censors less to block on, as actively probing clients commonly
returns few or no open ports. A censor may also be hesitant to block
client-to-client communication, as it could block peer-to-peer applications as
well as many video conferencing protocols. WebRTC is a
natural choice for a client-to-client transport in censorship circumvention,
and is already used in existing schemes like
Snowflake~\cite{snowflake}. \scheme could also use WebRTC as the
transport protocol, convincing the censor that two clients are communicating.

\TabApplications


\section{Implementation}
\label{sec:implementation}

We implemented \scheme and deployed a station at a mid-sized transit ISP tapping 
traffic from a 20~Gbps router. We used PF\_RING to
consume the 20~Gbps link, and feed it to a custom \textbf{detector} written in Rust. The
detector processes all packets and watches for new registrations. Once a registration 
is detected the local application is notified via an 
out-of-band ZMQ~\cite{zmq} connection, which provides the
registering client's IP address, the seed, and other configuration
information. We note that this is not along a critical timing path for 
proxying connections and no client packets are sent over ZMQ\@.

The detectors forwards all packets destined for a (registered) phantom host address to the local
\textbf{application} via tun interfaces and \texttt{iptables} DNAT rules that rewrite the destination IP,
allowing the local application to accept and respond to connections using the native
operating system's interface. Figure~\ref{fig:implementation} shows the overall
architecture of our implementation, which we describe in the following subsections.
% Along with the client?

\FigImplementation

\subsection{Detector}

% Our detector is a modified fork of the open source TapDance
% implementation~\cite{tapdance-source}.
We implemented our detector in approximately 1,800 lines of Rust, compared to
over 5,000 lines for TapDance (excluding from both auto-generated protobuf code).

To achieve performance needed to operate at 20~Gbps, we used
PF\_RING~\cite{pfring} to load balance incoming packets across 4~CPU cores,
which each run a dedicated detector process.
PF\_RING supports load balancing packets based on
either their flow (5-tuple), or their source/destination IPs, which allows
connections to be processed by a single process without
requiring communication across independent cores.

However, in \scheme, registration connections and phantom proxy connections
could end up being load balanced to different cores. In order for an individual
detector process to forward phantom proxy connections to the application, it must
know about the original registration, even if that registration was observed by a
different core.
To address this, we used Redis~\cite{redis} to allow each core's process to broadcast
(publish) newly registered decoys to the other cores so they can
add them to their local list of registered phantom host addresses. Broadcasting
registrations across all cores ensures that each detector process sees all
registrations, and can forward phantom proxy connections accordingly.

A second problem arises when considering how to \emph{timeout} unused phantom proxies
in the detector. When a phantom proxy is timed out, it no longer responds to any
active probes. A naive implementation might simply have each core timeout unused
phantom proxies after they go unused for a set time. However, this could leave
one core (that sees active proxy use) forwarding packets to the application, while
other cores (that do not see use) would timeout the proxy. A censor could probe the
phantom proxy and observe this behavior: if the censor's packets are processed
on a forwarding core, the censor can establish a TCP connection with the phantom
application. Otherwise, if they are processed on a timed out core, the censor's packets
will be ignored. Through multiple connections, the censor could use this strange
behavior (of intermittent TCP response) to identify and block potential phantom
proxies.

To address this issue of differing core timeouts, we implemented a new
load-balancing algorithm in
PF\_RING to select the core based only off the destination IP address of a
packet. This means that \emph{all} packets sent to a particular phantom proxy address
are processed by the same detector core, which allows the phantom proxy's timeout state
to be consistent regardless of what source attempts to connect to it.
%We still must use Redis to tell all of the cores of new
%registrations, but only one core will be ultimately responsible for processing all of
%the packets sent to a given phantom host, regardless of who sends it or when it is sent.


\subsection{Client}


%TODO: how many registration requests do we make? how long does it take?
We created a \scheme client and integrated it with the Psiphon~\cite{psiphon}
anticensorship client. Psiphon has millions of users in censored countries, and
we are in the early stages of rolling \scheme out to real-world users.

Our \scheme client is written in Golang, and uses the Refraction Networking tagging
schema (Section~\ref{sec:registration}) for
registration. We note that this protocol will be more difficult for censors to observe
than normal TapDance because it consists of only a single (complete) request, and the station does
not have to spoof packets as the decoy during registration, only passively
observe them. 

We implemented support for two of the transports in our client: Obfuscated SSH used by
Psiphon (Section~\ref{sec:ossh}) and our TLS Mask Site protocol
(Section~\ref{sec:mask-sites}). Our client signals which transport it will use
in the registration tag along with a flag indicating whether the
client supports IPv6, allowing IPv4-only clients to derive exclusively IPv4 phantom hosts.
After registration, the client connects to the derived
phantom host address, and speaks the specified transport protocol, which
tunnels between the client and either the mask site transport local to the 
station or Psiphon's backend servers. A SOCKS connection can be initiated through
this tunnel to allow for connection multiplexing.


\subsection{Application and Transports} 

We implemented our station-side application in about 500~lines of Golang. This includes
support for OSSH (via integration with Psiphon) and Mask Sites, both specifiable by the client
during registration. We note that support for other transport protocols (e.g. Obfs4 or WebRTC)
can be added as development continues. 

\subsubsection{OSSH}

Our \scheme implementation includes support for OSSH through integration with Psiphon. 
Client traffic is forwarded to a Psiphon server by using  \scheme as a  
transparent proxy. This symbiotic relationship provides \scheme with active 
and passive probe resistance, while preventing censors from being able to inexpensively
block Psiphon's backend servers individually. 


\subsubsection{Mask Sites}

We implemented a mask site mimicking proxy, that pretends to be a mask site
when actively probed by the censor. Once the station accepts accepts a connection 
for a registered flow, it initially acts as a transparent
proxy to a mask site specified by the client during registration. The
application parses the handshake, forwarding packets back and forth between
client and mask site without modification, extracting the server and client
randoms. The application attempts to decrypt the first application data record
from the client using a key derived from the secret seed, client, and server
randoms. We use the uTLS library~\cite{utls,tls-fingerprint} on both the application and client
to allow us to change the TLS secrets being used after the handshake.

\FigTapBandwidth

If the decryption is successful, the application switches to forwarding
(decrypted) data back and forth with a client-specified endpoint, such as a
SOCKS proxy, which can provide multiple secure connections over the single
connection to the phantom host.


\section{Evaluation}
\label{sec:evaluation}
% 1 page

%\TODO{Write (1 page)}

\FigUpload
\FigDownload

To evaluate our \scheme implementation, we compare its bandwidth and latency
to that of TapDance in a realistic ISP setting. We used a 20~Gbps
network tap at a mid-sized ISP and run both implementations on a 1U server with
an 8-core Intel Xeon E5-2640 CPU, 64GB of RAM, and a dual-port Intel X710 10GbE SFP+
network interface. A typical week of bandwidth seen on the tap is
shown in Figure~\ref{fig:tap-bandwidth}, ranging from 2.4~Gbps to peaks above
17~Gbps.

\subsection{Performance}

We evaluated the performance of a client from an India-based VPS.
Figures~\ref{fig:upload} and~\ref{fig:download} show the upload and download bandwidth as
measured by iperf for TapDance, our \scheme implementation (using the mask site application),
and a direct connection to our iperf server in the ISP's network.

TapDance must reconnect if the amount of data sent by the client
exceeds a short TCP window (typically on the order of 32~KBytes) or the
connection persists until a timeout (18-120 seconds). At each reconnect, the
TapDance client naively blocks until a new TLS connection to the decoy and
station has been established. Thus, when uploading files, TapDance has to create
a new TLS connection for every 32~KBytes of data it sends, limiting its average
upload bandwidth to around 0.1~Mbps due to the high overhead. In contrast,
our \scheme implementation is
able to maintain the same connection during large uploads, and achieves
performance inline with the direct connection, over 1400 times faster.

During download-only workloads, TapDance is able to better utilize the network,
but must still reconnect before the decoy times out. In our tests, we see
TapDance reconnect every 25 seconds, which can negatively impact the performance of
downloads or any real-time streaming applications. Again, our \scheme
implementation is able to maintain a single connection and provide the maximum
download rate without interruption, 14\% faster than TapDance.

We also measure the latency of repeated small requests. In both \scheme (using
the OSSH protocol) and
TapDance we establish a single session tunnel using our integrated Psiphon
client, and make 1000 requests through each using Apache Benchmark (ab). We find
that our India-based VPS throttles TLS but not OSSH, making TapDance twice as slow as
\scheme. We repeated these tests on a US-based VPS which does not have such
throttling, and show results in Figure~\ref{fig:latency}. TapDance's frequent
reconnects adds significant latency to about 10\% of requests. In addition, the
median latency of \scheme is about 19\% faster, due to the added
overhead of TLS and the complex path that TapDance data packets take through
the station compared to \scheme.

\FigLatency


\subsection{Address Selection}
\label{sec:addr-selection}

Phantom host IP addresses must be derived from network blocks that are routed (so they pass
the \scheme station) and contain other legitimate hosts (so that censors cannot
block the entire network without collateral damage).
Because of the large number of IPv6 addresses, even
moderately-sized network prefixes have astronomical numbers of addresses: a
single /32 prefix has $2^{96}$ possible addresses. Therefore, client-chosen
seeds have negligible probability of corresponding to addresses that are already
being used by legitimate hosts. This allows us to select phantom host addresses
from network prefixes that contain
legitimate hosts---crucial to discouraging the censor from blocking them
outright---without worry that registrations could interfere with legitimate
services.

%In addition, the use of IPv6 prevents censors from exhaustively probing
%potential phantom host network prefixes ahead of time to learn the full set of
%legitimate sites in the network, even from a single vantage point.
%Therefore, IPv6 phantom hosts could choose
%to respond to any client, and not just the original registering client.

\subsubsection{IPv4}
While \scheme works best with IPv6, it can also support IPv4, with some
careful caveats.

First, in IPv4, there are substantially fewer addresses,
allowing censors to potentially \textbf{enumerate all the network prefixes}
that pass by the ISP station, compose the list of innocuous sites,
and block other websites, as they are being summoned by \scheme.
To address this, \scheme
phantom hosts are firewalled from all IPs other than the client that registered
them, providing a reason why the address hasn't been seen in an enumerating scan,
conducted by a censor from a single vantage point.
Censors could attempt to scan the network from \emph{all} potential client
vantage points, by co-opting client IPs to perform scans---a behavior previously
observed by the Great Firewall of China to scan for Tor bridges~\cite{ensafi-tor}.
To prevent this, for IPv4 \scheme, we dynamically generate the TCP port of the
phantom host (along with its IP) from the registration seed, which further makes
exhaustive scans infeasible:
a censor that must enumerate from the vantage point of a /10 of client IPs (4~million IPs)
to a /16 (65K IPs) of potential phantom proxies on each of 65K potential ports would take nearly
50~years of scanning with ZMap at 10~Gbps. We note that while the use of
non-standard ports could potentially be suspicious, several successful
circumvention tools---including Psiphon~\cite{psiphon} and
\texttt{obfs4}~\cite{obfs4}---use random ports on their obfuscated protocols.
Finally, we note that censors that whitelist either standard ports or discovered
hosts from enumerations scans would over-block new services that came online after
their scans.

A second problem in IPv4 \scheme is that the limited range of IPs (and ports)
makes it possible for a censor to \textbf{pre-image the hash} used to derive the phantom
address from the seed. Even with the /16 of IPs and all 65K ports, in order to
find a seed for any desired address a censor
needs to only test an expected $2^{32}$ possible seeds.
The censor could then register a suspected
address, and see if it provides proxy access. If it does, the censor learns
there is no legitimate service there, and can block it. To combat this, we
allow only a single client to register for a particular phantom address at a
time. A censor could attempt to register all addresses in an attempt to deny
proxy service to legitimate users, but this would be easily observed at the
registration system, where rate limits via client puzzles or account-based fees
could be enforced.

Finally, legitimate \textbf{IPv4 addresses density} is much higher than IPv6,
increasing the potential for users to accidentally register seeds that derive
phantom addresses corresponding to live hosts. To address this, the station
sends probes to potential IPv4 phantom hosts during registration, and ignores the
registration if a real host responds. Censors that try to register specific
phantom proxies will be unable to distinguish if another user has registered it
or a legitimate host is there, as in both cases we ignore the censor's
registration. This also serves to prevent abuse by attackers that attempt
to use the \scheme station to interfere with innocuous services.


%We emphasize that TapDance is already
%vulnerable to active probing attacks~\cite{tapdance14} that \scheme defends
%against when using IPv6. However, in IPv4, there are substantially fewer
%addresses, allowing censors to easily enumerate network prefixes that pass by
%the \scheme station and measure legitimate sites. Furthermore, the small address
%space makes it much easier to pre-image the hash used to derive IP addresses
%from the seed. Registering a specific IPv4 address in an IPv4 /16 subnet will
%take only an expected $2^{16}$ hashes for the censor to achieve. This would let
%attackers register legitimate hosts as phantom hosts, potentially disrupting
%legitimate service. If the station refused to pick up for addresses that
%correspond to legitimate hosts (measured by scanning during registration), then
%censors could use this as an oracle for distinguishing legitimate sites from
%phantom hosts. Still, IPv4 \scheme offers many performance, flexibility, and
%simplicity benefits over TapDance, though they are both vulnerable to active
%probing attacks.


%While address utilization in IPv4 is quite high (all blocks have been allocated
%at the RIR level), the fraction of addresses that respond to TCP connections on
%a given port is quite low: even popular ports like 443 (use by TLS) have less
%than 2\% of IPv4 hosts respond to connection requests. This leaves a large
%number of hosts available to use as dark decoys. However, if a client registers
%a dark decoy address that is already happens to be used by an existing host,
%there will be multiple responses when the client tries to connect, and the
%connection will fail. However, this failure is still limited to the registering
%client, as the application only responds to the IP of the client that
%registered. In IPv6, the odds of picking a legitimate host are negligible: with
%a /32 prefix of IPv6, there are $2^{96}$ addresses to choose from.
%\nikita{/32 is pretty big, e.g. UIUC only has a /48}




\subsubsection{IPv6}
\FigIpBits

In IPv6 \scheme address enumeration and pre-image attacks are infeasible due to a large amount of
potential IP addresses.
Our ISP routes a /32 IPv6 prefix, which provides $2^{96}$ potential
phantom host IP addresses. However, IPv6 addresses often have long runs of 0
bits in them, and rarely use all 128-bits equally.
For instance, google.com has the address
%\texttt{2607:f8b0:400f:0806:0000:0000:0000:2004} (which can be shortened to
\texttt{2607:f8b0:400f:806::2004}, which only has 24 bits set to 1.
Censors might try to use this observation and block high entropy IPv6 addresses.

To measure and quantify this problem, we collected and analyzed 16 hours of
netflow data at our ISP tap. We extracted 4013 IPv6 addresses observed in the /32
IPv6 prefix routed by the ISP (out of 32,817 total observed). To confirm the
hypothesis that 0 bits are more common in IPv6 addresses, we counted the number
of bits set in each address. Figure~\ref{fig:ipbits} shows a histogram of the
number of bits set and compares it to the histogram of a uniformly random set of
addresses. (The random distribution's center is skewed from 64 due to
the number of set bits in our fixed /32 network prefix.) Although these
distributions are distinguishable, they do have significant overlap. Given
enough samples, a censor could trivially tell if the addresses were chosen
randomly or were legitimate hosts. However, a censor's job is significantly
harder, and they must tell from a single sample which distribution it comes
from. The presence of random-looking addresses makes it difficult for censors to
block such hosts outright.

% 7 bits set in 2001:48a8:: (would expect 16)

Prior work by Foremski et al.~\cite{foremski2016entropy} has developed models to
generate likely IPv6 addresses from a set of known addresses, useful for
discovering new hosts to scan given known ones. We use their Entropy/IP tool to
analyze the addresses we collected. Figure~\ref{fig:ipentropy} shows the
normalized entropy of each address 4-bit nibble and the total entropy (18.8 out
of 32). Nibbles that were constant across all addresses
(such as the /32 network prefix nibbles) have zero entropy, while those that
equally span the range of values have maximum entropy (normalized to 1). In our
addresses, we observe an entropy of over 75~bits, with more entropy in the later
segments of the address. While not quite the full 96~bits that uniformly random
would produce, this is still a significant amount for phantom hosts to hide in.
\looseness=-1

For a specific deployment, operators should be careful to observe the distribution of
addresses in the subnets they use, and possibly limit to randomizing ``realistic''
bits (e.g. the upper and/or last 32 bits within the given /32).
As an improvement, we could also use the Entropy/IP
tool~\cite{foremski2016entropy} to generate the random IPv6 phantom hosts from
the registration seed based on the Bayesian Network model created by the tool.



\section{Attacks and Defenses}
% 1 page
\label{sec:attacks}

In this section, we discuss several attacks a censor might attempt to either
block phantom hosts from being registered or used.


\subsection{Probing phantom hosts}
% censors could actively scan phantom hosts...we review how this works for obfs4, OSSH, masked sites individually
Censors may attempt to actively probe suspected phantom hosts to determine if
they are proxies or real hosts. China has been observed using exactly this technique to
discover existing proxies and Tor bridge
nodes~\cite{tor-bridge-blocking-blog,active-probe,ensafi-tor,china-blocking-tor}.
In response to China's active probing, Tor and other circumvention tool developers have developed
\emph{probe-resistant} protocols, such as \texttt{obfs4}~\cite{obfs4}, Obfuscated SSH
(OSSH)~\cite{ossh}, and Shadowsocks~\cite{shadowsocks}. Each of these protocols
require the client to know a secret distributed alongside the original
proxy address. Without knowledge of this secret, active-probing censors will not
receive any response from these hosts, making it difficult for censors to tell if
a server is a proxy or a non-responsive legitimate host.

\paragraph{Obfuscated SSH} Modern OSSH protocols are intended to be
probe-resistant. Censors that attempt to probe suspected OSSH servers without
knowledge of the secret receive no data response, making it difficult to
distinguish them from other non-responsive hosts. To confirm this, we use
ZMap~\cite{zmap13} to scan over 1 billion random IP/port combinations, and sent 25
random bytes (corresponding to the OSSH handshake) to the approximately 800,000
servers that responded. We expect very few of these to actually be OSSH
servers as they are simply random servers on random TCP ports.
However, over 99.4\% of them did not respond with any data, behavior mirrored by
OSSH servers.
Furthermore, 7.42\% of servers closed the connection with a TCP RST
after we send our random data, a response we also see with OSSH. While there may
be other ways to differentiate OSSH servers from others online, our tests
suggest censors could face steep false-positive rates in identifying OSSH
servers with active probing.

\FigIpEntropy

%TODO: how many servers in zmap look like OSSH? e.g. we send them 23 random
%bytes and then they don't respond with data. 99.46% (793789 out of 798032)
% If we send 25 bytes (~OSSH handshake size...), OSSH server responds with RST.
% zmap: 28.42% respond with RST within 4 secs. Only 7.49% within 

\paragraph{\texttt{obfs4}}
Unlike previous versions of obfsproxy, the \texttt{obfs4} protocol is designed to
be resistant to active probing
attacks, requiring the client prove knowledge of a secret before the server will
respond. We verified that naive active probing attacks (where we attempt to
connect to an \texttt{obfs4} server without knowledge of the secret and see if
it provides proxy access) do not work
against \texttt{obfs4}. In addition, although China is effective at blocking
\texttt{obfs3}, the more recent probe-resistant \texttt{obfs4} remains a viable
proxy in the country.\footnote{E.g., \url{https://metrics.torproject.org/userstats-bridge-combined.html?start=2019-06-27&end=2019-09-25&country=cn} shows \texttt{obfs4} clients from China successfully using Tor.}


\paragraph{Mask sites}
The censor could also attempt to fingerprint a masked site and compare it to a
suspected \scheme application. For instance, if a phantom host IP responds to a
censors' probes
pretending to be \texttt{example.com}, the censor could probe real instances
of \texttt{example.com} on different ports and see how it responds. Then, the
censor can probe the phantom host IP, and see if it responds similarly (e.g. with
the same set of open ports and payloads for certain kinds of probes). To defend
against this, we forward \emph{all} traffic destined to the phantom host to the
masked site, including ports that are not relevant to the proxy application
(e.g. non 443). This ensures that above the TCP layer, we appear to be the mask
site. However, there may be differences in TCP/IP implementations, for instance,
how IP IDs are incremented, or how TCP timestamps are incremented (or supported
at all) that may be different from the mask site. To combat this, we can filter
mask sites by those that have identical TCP/IP stacks to ours, as we use a
common Linux implementation. We also note that this attack only applies when we
use the mask site as an application, and that \scheme can support other
applications (e.g. obfsproxy, WebRTC, etc) that do not have this issue.
\looseness=-1

We acknowledge that perfect mimicry of the real site is likely infeasible:
Houmansadr et al.~\cite{houmansadr-parrot} demonstrated the difficulty in fully
mimicking known applications, showing that staying fully-feature compatible is
an expensive and potentially intractable problem for circumvention systems.
However, their study focuses on \emph{application-specific} mimicry, used by
circumvention tools like CensorSpoofer, StegoTorus, and Skypemorph. These tools
generally attempt to mimic a specific protocol used by a complex application
such as Skype,
where only one or a handful of official popular clients are used. Houmansadr et
al.~\cite{houmansadr-parrot} show that such mimicry is difficult in practice due
to the complexity and opaqueness of specifications, side protocols that
applications may use, and intra- and inter-dependence on connections and other
protocols.

In contrast, mask sites have
the advantage that we can mimic any sites from a large set of heterogeneous real
websites, making it harder for a censor to fully fingerprint and characterize
\emph{all} potential mask sites. As websites may themselves use distributed
or heterogeneous server implementations, it could be more difficult for a
censor to block all mask site application use.
Nonetheless, it is still possible for censors to
use active probing attacks to detect either protocol feature, payload size, or
timing differences between mask sites and the real sites they attempt to mimic.

%This general issue remains an open problem in censorship circumvention; however,
%if solved, \scheme can use it to thwart active probing attacks in a useable
% and flexible system.

\subsection{Passive identification}
Censors might also attempt to use passive methods to distinguish and block communication
with registration decoys or phantom hosts. For example, 
Website Fingerprinting~\cite{wang2014effective,hayes2016k,sirinam2018deep} (WF)
uses the patterns of encrypted traffic to identify which website a client is
connected to. WF uses a classifier to label the traffic as belonging to one of
several known websites, or (in some variants), an unknown or background class.
Though WF is commonly studied in the context of anonymous web browsing, a censor
could also use WF to detect \scheme applications by distinguishing known traffic
patterns of legitimate website use from traffic generated by \scheme (unknown
class). Alternatively, the censor could monitor traffic for patterns consistent
with tunneled access to a set of blocked websites.

Wang et al.~\cite{wang2015seeing} demonstrated several effective classifiers
that can passively distinguish normal traffic from obfuscated circumvention
protocols including \texttt{obfs3}, \texttt{obfs4}, Format-transforming
encryption~\cite{fte}, and meek~\cite{meek}. However, despite the low false
positive rate of these classifiers, Wang et~al.~\cite{wang2015seeing} caution
that the base rate of normal traffic compared to obfuscated traffic would force
censors that employ such attacks to suffer significant collateral damage in
degrading performance and reliability of legitimate traffic.
Indeed, to date, censors have not been observed using WF or other
passive techniques, possibly due to the inaccuracy of these identification
techniques in practice. Even small false positive rates means blocking mostly legitimate
connections, and false negatives could allow clients to retry until they gain
access.


More importantly, \scheme applications offer great flexibility in deploying
traffic analysis defenses; for example, traffic shaping strategies such as
implemented in Slitheen~\cite{slitheen16} could be easily employed in \scheme.
\scheme clients could also choose from a large set of potential applications,
forcing censors to have to block access to all of them to block use.
%Furthermore, \scheme applications are not limited to mimicking websites, and can
%support any (or even a combination of) protocols. Finally, if encrypted SNI can
%be used (\cref{esni}), the censor would not be able to build up a traffic
%profile of a legitimate site since its identity would be encrypted.



\subsection{Blocking registration}
To make registration more difficult, censors could block TLS connections to all of the
limited decoys available in a deployment. Using TapDance's current deployment,
this would involve blocking over 1500 sites. We note that such an attack would
completely disable all existing Refraction Networking schemes, as none work
without being able to access legitimate decoys past the station. In \scheme,
this would only block new registrations, and would not impact users that
previously registered. Furthermore, registrations could also occur over email,
or over lower-bandwidth covert channels, such as port (or even IP) knocking past
the station, that would be more difficult for the censor to block.
%Cirripede previously used a registration protocol that sent covert information via initial
%sequence numbers in arbitrary TCP connections, though we note this solution
%generally requires clients to have root access to their device to control the
%initial sequence numbers. Since most mobile users do not have such control, we
%suggest other methods be used instead.


\subsection{ICMP}
Censors can use ping or traceroute utilities (via ICMP) to probe potential phantom
hosts. Because there is (usually) no host at the phantom host address, these
probes will timeout and produce no response. They might also produce
``Destination Unreachable'' responses from routers depending on how they are
configured. We performed a scan of 10~million IPv6 addresses in a routable /32
prefix to see if it is common to respond with such tell-tale ICMP messages for
unused messages. We found only 0.016\% of addresses responded with any ICMP
messages (mainly ``Time Exceeded'' and ``Destination Unreachable'').

Many legitimate hosts and routers do not respond to or forward ICMP packets, and
it is common for firewalls to block traceroutes from penetrating inside
networks. Thus, simply ignoring ICMP messages (or low TTL packets that might be
used by traceroute) may be a viable strategy. % We should evaluate this claim...
Alternatively, we could spoof responses to convince an adversary that a 
phantom host is part of a particular network. However, this strategy requires careful
consideration of what network makes sense for a mask site to be in. Also, the
censor may try to probe for addresses around the phantom host (but still likely to
be in the same network), which must also be responded to.



%-Fingerprinting Masked site vs Dark decoy application
%-ICMP



\input{related}
% 0.5-0.75 page

\section{Conclusion and Future Work}
% 0.5 page

\scheme provides a much larger degree of engineering flexibility than previous
Refraction Networking schemes. Due to its modular design, different registration
protocols and proxy transports can be used interchangeably by the client. The
flexibility of proxy transports and simplicity of registration allows \scheme to
incorporate state of the art censorship circumvention tools and resist 
nation-state censors. 

One obvious future direction is to study new options for registration and proxy transport. For instance, while 
\scheme currently uses a TapDance- style covert channel for registration, we could potentially 
cut down on the overhead of one-time registration by using port-knocking or using a 
Telex-style~\cite{telex11} tag (in the ClientHello rather than Application Data).

\paragraph{Client-side applications}
\scheme provides an interesting opportunity to explore
\emph{client mimicking} phantom hosts. Rather than pretend to be a server (e.g.,
a mask site), our transport itself could connect to a newly registered client
from the phantom host address. Possible protocols could include WebRTC, mentioned in
Section~\ref{sec:webrtc}, or other peer-to-peer protocols such as BitTorrent,
Skype, or Bitcoin.

\paragraph{Traffic analysis}
\scheme could also support applications that tradeoff performance for
observability. While Slitheen offers ideal mimicry of decoys, it comes at a high
cost of overhead. \scheme transports such as mask site could implement Slitheen
in order to perfectly mimic the decoy site's latency, packet timings, and payload
sizes. In addition, careful choice of mask sites may allow for higher
performance, as sites with more replaceable content can carry more covert data.

\paragraph{Long-term deployment}
Ultimately, the goal for Refraction Networking protocols is to be useful in
circumventing censorship. While it has taken many years for research
protocols to mature, we are excited to see schemes like TapDance deployed in
practice~\cite{frolov2017isp}. We believe \scheme can be even easier to deploy
at scale, and we hope to leverage the existing success of TapDance to place \scheme
stations at real ISPs.


%%-------------------------------------------------------------------------------
%\section*{Availability}
%%-------------------------------------------------------------------------------
%
%USENIX program committees give extra points to submissions that are
%backed by artifacts that are publicly available. If you made your code
%or data available, it's worth mentioning this fact in a dedicated
%section.

%-------------------------------------------------------------------------------

\begin{acks}
  The authors thank the incredible partner organizations that have
  made deployment of Refraction Networking a reality, especially Merit
  Network and Psiphon. We also thank the
  University of Colorado IT Security and Network Operations
  staff. This material is based in part upon work supported by the
  U.S. National Science Foundation under Awards
  CNS-1518888 and OAC-1925476.
\end{acks}

\bibliographystyle{ACM-Reference-Format}
\balance
\bibliography{biblio}

%\appendix
%\input{rebuttal}

\end{document}
